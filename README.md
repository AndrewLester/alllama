# llama-server

```
[ENV=production] python3 server.py -s server -m models/meta-llama-3-70B-instruct-IQ2_XS.gguf
```
